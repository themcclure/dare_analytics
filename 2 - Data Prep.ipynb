{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prep the data for processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from urllib.parse import parse_qs\n",
    "from dateutil import relativedelta\n",
    "\n",
    "# prep the environment\n",
    "data_dir = Path.cwd() / \"data\"\n",
    "# uat_file_name = \"ssrs_week_1_2.csv\"\n",
    "uat_file_name = \"ssrs_week_1.csv\"\n",
    "uat_file = data_dir / uat_file_name\n",
    "data_file = data_dir / \"uat_data.pkl\"\n",
    "uat_start = datetime.datetime(2019, 7, 22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load the UAT runtime data\n",
    "if uat_file.exists():\n",
    "    raw_df = pd.read_csv(uat_file)\n",
    "else:\n",
    "    print(f\"Processed data missing, please run the Data Prep notebook first.\")\n",
    "    exit(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Key Columns:\n",
    "- All (for now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# select key columns\n",
    "uat_df = raw_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Columns:\n",
    "1. DateTime columns = StartTime, EndTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uat_df['StartTime'] = pd.to_datetime(uat_df['StartTime'], infer_datetime_format=True)\n",
    "uat_df['StopTime'] = pd.to_datetime(uat_df['StopTime'], infer_datetime_format=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Invalid Rows:\n",
    "1. Rows with NULL in the following columns:\n",
    "  - User\n",
    "  - ReportPath\n",
    "1. Rows with StartTime before the start of UAT\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# clean invalid the rows\n",
    "uat_df.dropna(subset=['User', 'ReportPath'], inplace=True)\n",
    "\n",
    "# clean pre-UAT rows\n",
    "uat_df = uat_df[uat_df['StartTime'] >= uat_start]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Derived Fields:\n",
    "1. DurationTotal - the sum of the 3 duration columns\n",
    "1. DurationTotalSec - converting DurationTotal to seconds\n",
    "1. DurationDataRetrievalSec - converting DurationDataRetrieval to seconds\n",
    "1. DurationProcessingSec - converting DurationProcessing to seconds\n",
    "1. DurationRenderingSec - converting DurationRendering to seconds\n",
    "1. ReportGroup - the broad group of users (directory)\n",
    "1. ReportName - the name portion of the report\n",
    "1. Agency - the Agency of the user who ran the report\n",
    "1. Dims - report on how many times report execution called a /*Dim record \n",
    "   (then remove the /*Dim rows from the DataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 1267 /*Dim records, making an average of 2.04 /*Dim calls per ExecutionId\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mcclure/PycharmProjects/dare_analytics/venv/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/mcclure/PycharmProjects/dare_analytics/venv/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/mcclure/PycharmProjects/dare_analytics/venv/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/mcclure/PycharmProjects/dare_analytics/venv/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/mcclure/PycharmProjects/dare_analytics/venv/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/mcclure/PycharmProjects/dare_analytics/venv/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/mcclure/PycharmProjects/dare_analytics/venv/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/mcclure/PycharmProjects/dare_analytics/venv/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# create derived fields\n",
    "uat_df['DurationTotal'] = uat_df['DurationDataRetrieval'] + uat_df['DurationProcessing'] + uat_df['DurationRendering']\n",
    "uat_df['DurationTotalSec'] = uat_df['DurationTotal'] / 1000\n",
    "uat_df['DurationDataRetrievalSec'] = uat_df['DurationDataRetrieval'] / 1000\n",
    "uat_df['DurationProcessingSec'] = uat_df['DurationProcessing'] / 1000\n",
    "uat_df['DurationRenderingSec'] = uat_df['DurationRendering'] / 1000\n",
    "uat_df[['ReportGroup', 'ReportName']] = uat_df['ReportPath'].str.extract('^/(?P<UserGroup>.*)/(?P<ReportName>.*$)')[['UserGroup', 'ReportName']]\n",
    "\n",
    "# set field types\n",
    "uat_df['ReportGroup'] = uat_df['ReportGroup'].astype('category')\n",
    "uat_df['ReportName'] = uat_df['ReportName'].astype('category')\n",
    "\n",
    "# Add Agency\n",
    "uat_df.User.replace('Administrator', 'UATUserDARe', inplace=True)\n",
    "uat_df.User.replace('UATUserOrca', 'UATUserORCA', inplace=True)\n",
    "uat_df['Agency'] = uat_df['User'].str.extract('.*UATUser(?P<Agency>.*)$')\n",
    "\n",
    "# Filter out Dim records\n",
    "dim_list = ['/AgencyDim', '/BranchDim', '/CardGroupDim','/InstitutionDim', '/ParticipantDim']\n",
    "dim_df = uat_df[uat_df.ReportPath.isin(dim_list)]\n",
    "uat_df = uat_df[~uat_df.ReportPath.isin(dim_list)]\n",
    "print(f\"Filtered out {len(dim_df)} /*Dim records, making an average of {(len(dim_df) / len(uat_df)):.2f} /*Dim calls per ExecutionId\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the Query Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_num_institutions = lambda x: len(parse_qs(x)['InstitutionDimKey']) if type(x) == str and 'InstitutionDimKey' in parse_qs(x).keys() else 0\n",
    "\n",
    "def param_query_months(param_string):\n",
    "    date_format = '%m/%d/%Y %I:%M:%S %p'\n",
    "    if type(param_string) != str:\n",
    "        return None\n",
    "    params = parse_qs(param_string)\n",
    "    if 'FromDate' not in params.keys() or 'ToDate' not in params.keys():\n",
    "        return None\n",
    "    rdelta = relativedelta.relativedelta(datetime.datetime.strptime(params['ToDate'][0], date_format),\n",
    "                                         datetime.datetime.strptime(params['FromDate'][0], date_format))\n",
    "    if rdelta.days > 16:\n",
    "        rdelta.months += 1\n",
    "    months = rdelta.years * 12 + rdelta.months\n",
    "    return months\n",
    "\n",
    "uat_df['ParamNumInstitutions'] = uat_df['Parameters'].apply(param_num_institutions)\n",
    "uat_df['ParamNumMonths'] = uat_df['Parameters'].apply(param_query_months)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the processed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated /Users/mcclure/PycharmProjects/dare_analytics/data/uat_data.pkl on 2019-08-07 17:03:03.553195\n"
     ]
    }
   ],
   "source": [
    "# save the loaded data\n",
    "uat_df.to_pickle(data_file)\n",
    "print(f\"Updated {data_file} on {datetime.datetime.now()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
