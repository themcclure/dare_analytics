{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prep the data for processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from urllib.parse import parse_qs\n",
    "from dateutil import relativedelta\n",
    "\n",
    "# prep the environment\n",
    "data_dir = Path.cwd() / \"data\"\n",
    "uat_file_name = \"ssrs_week_1_2.csv\"\n",
    "# uat_file_name = \"ssrs_week_1.csv\"\n",
    "uat_file = data_dir / uat_file_name\n",
    "data_file = data_dir / \"uat_data.pkl\"\n",
    "uat_start = datetime.datetime(2019, 7, 22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load the UAT runtime data\n",
    "if uat_file.exists():\n",
    "    raw_df = pd.read_csv(uat_file)\n",
    "else:\n",
    "    print(f\"Processed data missing, please run the Data Prep notebook first.\")\n",
    "    exit(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Columns:\n",
    "Normalize (rename) columns to be in line with original column names.\n",
    "If different column names are produced by different extracts, add them to the mapping here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "column_map = {'InstanceName': 'Server', 'ItemPath': 'ReportPath', 'UserName': 'User', 'TimeStart': 'StartTime', \n",
    "              'TimeEnd': 'StopTime', 'TimeDataRetrieval': 'DurationDataRetrieval', \n",
    "              'TimeProcessing': 'DurationProcessing', 'TimeRendering': 'DurationRendering', 'Status': 'ResultStatus'}\n",
    "uat_df = raw_df.rename(columns=column_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Columns:\n",
    "1. DateTime columns = StartTime, EndTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uat_df['StartTime'] = pd.to_datetime(uat_df['StartTime'], infer_datetime_format=True)\n",
    "uat_df['StopTime'] = pd.to_datetime(uat_df['StopTime'], infer_datetime_format=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Invalid Rows:\n",
    "1. Rows with NULL in the following columns:\n",
    "  - User\n",
    "  - ReportPath\n",
    "1. Rows with StartTime before the start of UAT\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# clean invalid the rows\n",
    "uat_df.dropna(subset=['User', 'ReportPath'], inplace=True)\n",
    "\n",
    "# clean pre-UAT rows\n",
    "uat_df = uat_df[uat_df['StartTime'] >= uat_start]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Derived Fields:\n",
    "1. DurationTotal - the sum of the 3 duration columns\n",
    "1. DurationTotalSec - converting DurationTotal to seconds\n",
    "1. DurationDataRetrievalSec - converting DurationDataRetrieval to seconds\n",
    "1. DurationProcessingSec - converting DurationProcessing to seconds\n",
    "1. DurationRenderingSec - converting DurationRendering to seconds\n",
    "1. ReportGroup - the broad group of users (directory)\n",
    "1. ReportName - the name portion of the report\n",
    "1. Agency - the Agency of the user who ran the report\n",
    "1. Dims - report on how many times report execution called a /*Dim record \n",
    "   (then remove the /*Dim rows from the DataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 2989 /*Dim records, making an average of 2.05 /*Dim calls per ExecutionId\n"
     ]
    }
   ],
   "source": [
    "# create derived fields\n",
    "uat_df['DurationTotal'] = uat_df['DurationDataRetrieval'] + uat_df['DurationProcessing'] + uat_df['DurationRendering']\n",
    "uat_df['DurationTotalSec'] = uat_df['DurationTotal'] / 1000\n",
    "uat_df['DurationDataRetrievalSec'] = uat_df['DurationDataRetrieval'] / 1000\n",
    "uat_df['DurationProcessingSec'] = uat_df['DurationProcessing'] / 1000\n",
    "uat_df['DurationRenderingSec'] = uat_df['DurationRendering'] / 1000\n",
    "uat_df[['ReportGroup', 'ReportName']] = uat_df['ReportPath'].str.extract('^/(?P<UserGroup>.*)/(?P<ReportName>.*$)')[['UserGroup', 'ReportName']]\n",
    "\n",
    "# set field types\n",
    "uat_df['ReportGroup'] = uat_df['ReportGroup'].astype('category')\n",
    "uat_df['ReportName'] = uat_df['ReportName'].astype('category')\n",
    "\n",
    "# uat_df.User.replace('administrator', 'Administrator', inplace=True)\n",
    "# uat_df.User.replace('Administrator', 'UATUserDARe', inplace=True)\n",
    "# uat_df.User.replace('REPORTAD\\\\UATUserOrca', 'REPORTAD\\\\UATUserORCA', inplace=True)\n",
    "# Attempt to parse out the Agency from the username\n",
    "uat_df['Agency'] = uat_df['User'].str.extract('.*UATUser(?P<Agency>.*)$')\n",
    "# Add Agency of known users, explicitly\n",
    "dare_users = ['REPORTAD\\\\UATUserOrca', 'REPORTAD\\\\UATUserOrca2', 'Administrator', 'administrator', \n",
    "              'REPORTAD\\\\ClaireC', 'REPORTAD\\\\RafaelE', 'REPORTAD\\\\RodrigoB']\n",
    "uat_df.loc[uat_df['User'].isin(dare_users), 'Agency'] = 'DARe'\n",
    "\n",
    "# Filter out Dim records\n",
    "dim_list = ['/AgencyDim', '/BranchDim', '/CardGroupDim','/InstitutionDim', '/ParticipantDim']\n",
    "dim_df = uat_df[uat_df.ReportPath.isin(dim_list)]\n",
    "uat_df = uat_df[~uat_df.ReportPath.isin(dim_list)]\n",
    "print(f\"Filtered out {len(dim_df)} /*Dim records, making an average of {(len(dim_df) / len(uat_df)):.2f} /*Dim calls per ExecutionId\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the Query Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_num_institutions = lambda x: len(parse_qs(x)['InstitutionDimKey']) if type(x) == str and 'InstitutionDimKey' in parse_qs(x).keys() else 0\n",
    "\n",
    "def param_query_months(param_string):\n",
    "    date_format = '%m/%d/%Y %I:%M:%S %p'\n",
    "    if type(param_string) != str:\n",
    "        return None\n",
    "    params = parse_qs(param_string)\n",
    "    if 'FromDate' not in params.keys() or 'ToDate' not in params.keys():\n",
    "        return None\n",
    "    rdelta = relativedelta.relativedelta(datetime.datetime.strptime(params['ToDate'][0], date_format),\n",
    "                                         datetime.datetime.strptime(params['FromDate'][0], date_format))\n",
    "    if rdelta.days > 16:\n",
    "        rdelta.months += 1\n",
    "    months = rdelta.years * 12 + rdelta.months\n",
    "    return months\n",
    "\n",
    "uat_df['ParamNumInstitutions'] = uat_df['Parameters'].apply(param_num_institutions)\n",
    "uat_df['ParamNumMonths'] = uat_df['Parameters'].apply(param_query_months)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the processed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated /Users/mcclure/PycharmProjects/dare_analytics/data/uat_data.pkl on 2019-08-08 13:58:08.111120\n"
     ]
    }
   ],
   "source": [
    "# save the loaded data\n",
    "uat_df.to_pickle(data_file)\n",
    "print(f\"Updated {data_file} on {datetime.datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
